{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Lab\n",
    "\n",
    "In the previous lab we have constructed a processing pipeline using `sklearn` for the titanic dataset. At this point you should have a set of features ready for consumption by a Logistic Regression model.\n",
    "\n",
    "In this la we will use the pre-processing pipeline you have created and combine it with a classification model.\n",
    "\n",
    "\n",
    "We have imported this titanic data into our PostgreSQL instance that you can find connecting here:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's load a few things:\n",
    "\n",
    "- standard packages\n",
    "- the training set from lab 2.3\n",
    "- the union we have saved in lab 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  \\\n",
       "0      0            1         0       3   \n",
       "1      1            2         1       1   \n",
       "2      2            3         1       3   \n",
       "3      3            4         1       1   \n",
       "4      4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM train', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator Imputer from version 0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator StandardScaler from version 0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator Pipeline from version 0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator FeatureUnion from version 0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import dill\n",
    "\n",
    "with gzip.open('../../assets/union.dill.gz') as fin:\n",
    "    union = dill.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's create the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Pipeline\n",
    "\n",
    "Combine the union you have created in the previous lab with a LogisticRegression instance. Notice that a `sklearn.pipeline` can have an arbitrary number of transformation steps, but only one, optional, estimator step as the last one in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model = make_pipeline(union, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model\n",
    "Use `X_train` and `y_train` to fit the model.\n",
    "Use `X_test` to generate predicted values for the target variable and save those in a new variable called `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('columnselector', ColumnSelector(columns='Age')), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training model with x_train and y_train\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predicted values for target variable\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the model accuracy\n",
    "\n",
    "1. Use the `confusion_matrix` and `classification_report` functions to assess the quality of the model.\n",
    "- Embed the results of the `confusion_matrix` in a Pandas dataframe with appropriate column names and index, so that it's easier to understand what kind of error the model is incurring into.\n",
    "- Are there more false positives or false negatives? (remember we are trying to predict survival)\n",
    "- How does that relate to what the `classification_report` is showing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Dead</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dead</th>\n",
       "      <td>154</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>37</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Dead  Predicted Survived\n",
       "Dead                 154                  21\n",
       "Survived              37                  83"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confus_mat = confusion_matrix(y_test, y_pred)\n",
    "id1 = ['Dead', 'Survived']\n",
    "column = ['Predicted Dead', 'Predicted Survived']\n",
    "df1 = pd.DataFrame(confus_mat, index=id1, columns=column)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.84       175\n",
      "          1       0.80      0.69      0.74       120\n",
      "\n",
      "avg / total       0.80      0.80      0.80       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a higher amount of false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improving the model\n",
    "\n",
    "Can we improve the accuracy of the model?\n",
    "\n",
    "One way to do this is to use tune the parameters controlling it.\n",
    "\n",
    "You can get a list of all the model parameters using `model.get_params().keys()`.\n",
    "\n",
    "Discuss with your team which parameters you could try to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['featureunion__pipeline-2__truefalsetransformer',\n",
       " 'featureunion__getdummiestransformer__columns',\n",
       " 'featureunion__pipeline-2__truefalsetransformer__flag',\n",
       " 'featureunion__pipeline-1__standardscaler__copy',\n",
       " 'featureunion__transformer_weights',\n",
       " 'featureunion__pipeline-3__standardscaler__with_mean',\n",
       " 'featureunion__pipeline-1__columnselector__columns',\n",
       " 'logisticregression__dual',\n",
       " 'featureunion',\n",
       " 'featureunion__pipeline-3__standardscaler__with_std',\n",
       " 'featureunion__transformer_list',\n",
       " 'featureunion__pipeline-3__steps',\n",
       " 'logisticregression__multi_class',\n",
       " 'featureunion__pipeline-2__columnselector',\n",
       " 'logisticregression',\n",
       " 'featureunion__pipeline-1__imputer__axis',\n",
       " 'featureunion__pipeline-1__imputer__strategy',\n",
       " 'logisticregression__random_state',\n",
       " 'logisticregression__verbose',\n",
       " 'featureunion__pipeline-1__standardscaler__with_std',\n",
       " 'featureunion__pipeline-1__standardscaler',\n",
       " 'featureunion__pipeline-1__steps',\n",
       " 'logisticregression__class_weight',\n",
       " 'logisticregression__intercept_scaling',\n",
       " 'featureunion__pipeline-1__standardscaler__with_mean',\n",
       " 'logisticregression__n_jobs',\n",
       " 'featureunion__pipeline-2__columnselector__columns',\n",
       " 'logisticregression__max_iter',\n",
       " 'featureunion__pipeline-1',\n",
       " 'featureunion__pipeline-2',\n",
       " 'featureunion__pipeline-3',\n",
       " 'featureunion__n_jobs',\n",
       " 'featureunion__pipeline-1__imputer__copy',\n",
       " 'featureunion__pipeline-2__steps',\n",
       " 'logisticregression__warm_start',\n",
       " 'logisticregression__solver',\n",
       " 'logisticregression__fit_intercept',\n",
       " 'featureunion__pipeline-1__imputer__verbose',\n",
       " 'featureunion__pipeline-3__columnselector__columns',\n",
       " 'logisticregression__penalty',\n",
       " 'featureunion__pipeline-1__columnselector',\n",
       " 'logisticregression__C',\n",
       " 'featureunion__pipeline-3__standardscaler__copy',\n",
       " 'featureunion__pipeline-1__imputer__missing_values',\n",
       " 'featureunion__pipeline-1__imputer',\n",
       " 'featureunion__getdummiestransformer',\n",
       " 'steps',\n",
       " 'featureunion__pipeline-3__columnselector',\n",
       " 'logisticregression__tol',\n",
       " 'featureunion__pipeline-3__standardscaler']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can systematically probe parameter combinations by using the `GridSearchCV` function. Implement a new classifier that searches the best parameter combination.\n",
    "\n",
    "1. How will you choose the grid granularity?\n",
    "1. How can you prevent the grid to exponentially grow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnay/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(model, param_grid = {\"logisticregression__C\":[0.01,0.02,0.03,0.05, 0.1,0.2,0.3,0.5,\n",
    "                                                          1.0,2.0,3.0,5.0, 10.0,20.0,30.0,50.0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('columnselector', ColumnSelector(columns='Age')), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__C': [0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.5, 1.0, 2.0, 3.0, 5.0, 10.0, 20.0, 30.0, 50.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Assess the tuned model\n",
    "\n",
    "A tuned grid search model stores the best parameter combination and the best estimator as attributes.\n",
    "\n",
    "1. Use these to generate a new prediction vector `y_pred`.\n",
    "- Use the `confusion matrix`and `classification_report` to assess the accuracy of the new model.\n",
    "- How does the new model compare with the old one?\n",
    "- What else could you do to improve the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 2.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7936241610738255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Logistic Regression:\n",
      "[[154  21]\n",
      " [ 36  84]]\n",
      "\n",
      "Tuned Logistic Regression:\n",
      "          Predicted Dead  Predicted Survived\n",
      "Dead                 154                  21\n",
      "Survived              36                  84\n",
      "\n",
      "Tuned VS Simple:\n",
      "          Predicted Dead  Predicted Survived\n",
      "Dead                   0                   0\n",
      "Survived               0                   0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "idx = ['Dead', 'Survived']\n",
    "col = ['Predicted Dead', 'Predicted Survived']\n",
    "cmdf1 = pd.DataFrame(cm, index=idx, columns=col)\n",
    "print \"Simple Logistic Regression:\"\n",
    "print cm\n",
    "print\n",
    "\n",
    "print \"Tuned Logistic Regression:\"\n",
    "print cmdf1\n",
    "print\n",
    "\n",
    "print \"Tuned VS Simple:\"\n",
    "print cmdf1 - cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.84       175\n",
      "          1       0.80      0.70      0.75       120\n",
      "\n",
      "avg / total       0.81      0.81      0.80       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy went up slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "What would happen if we used a different scoring function? Would our results change?\n",
    "Choose one or two classification metrics from the [sklearn provided metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) and repeat the grid_search. Do your result change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
